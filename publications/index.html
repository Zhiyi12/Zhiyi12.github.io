---
layout: default
title: publications
home: passive
publications: active
cv: passive
notes: passive
contact: passive
description: Current CV for Zhiyi Zhao, a deep learning engineer, project manager, and web noodler living and working in UK.
---





<h1 id="publication">Selected Publications</h1>
<h2>Please check my <a href="https://dsl-lab.github.io/">Deep Structured Learning Lab</a> website and <a
    href="http://scholar.google.com/citations?user=2wrS35MAAAAJ&amp;hl=en&amp;oi=ao">Google Scholar</a> for up-to-date publications!</h2>

<b>*</b> below indicates equal contribution<br />

<table border="0" cellspacing="10" cellpadding="2">
<!-- paper -->

    <!-- paper -->
    <tr>
            <td valign="center">
                    <center>
                            <a href="https://users.wpi.edu/~yli15/Includes/21_CDC21_AMAGAIL.pdf"><img
                                            src="imgs/glass.png" alt="Link" width="200px" /></a>
                    </center>
            </td>

            <td valign="center">
                    <a href="https://users.wpi.edu/~yli15/Includes/21_CDC21_AMAGAIL.pdf">YOLOv5s-Transformer: Improved YOLOv5 Network for Real-Time Detection of Cigarette Smoking Based
                        on Image processing<br /></a>
                        Z. Zhao and Y. Zhao.<br />
                    <em>Conference of IEEE World, 2023</em> (<b>CDC</b>), 2021<br />
            </td>
    </tr>

    <!-- paper -->
    <tr>
            <td valign="center">
                    <center>
                            <a href="https://arxiv.org/abs/2101.06653"><img src="imgs/glass.png"
                                            alt="Link" width="200px" /></a>
                    </center>
            </td>

            <td valign="center">
                    <a href="https://arxiv.org/abs/2101.06653">Plug-and-Play Self-Distillation for Multimodal Sentiment Analysis with Incomplete Modalities<br /></a>
                    Z. Zhao and Z. Ge.<br />
                    <em>The Association for the Advancement of Artificial Intelligence, 2025</em>
                    (<b>IROS</b>), 2021<br />
            </td>
    </tr>

    <!-- paper -->
    <tr>
            <td valign="center">
                    <center>
                            <a href="https://arxiv.org/abs/2101.02385"><img src="imgs/spaconvgnn.png"
                                            alt="Link" width="200px" /></a>
                    </center>
            </td>

            <td valign="center">
                    <a href="https://arxiv.org/abs/2101.02385"> Using Machine Learning and Bayesian-based Hyperparameter Tuning (RFBOCV): A Predictive Model for
                        Initial Public Offering (IPO) in the Hong Kong Stock Market<br /></a>
                        Z. Zhao and X. Liu<br />
                    <em>Journal of Mathematics</em>
                    (<b>IROS</b>), 2024<br />
            </td>
    </tr>

    <!-- paper -->
    <tr>
            <td valign="center">
                    <center>
                            <a href="https://arxiv.org/abs/2002.03629"><img
                                            src="imgs/fast_nonlinear_solver.gif" alt="Link"
                                            width="200px" /></a>
                    </center>
            </td>

            <td valign="center">
                    <a href="https://arxiv.org/abs/2002.03629">Transformer Adapter for Efficient Static-to-Dynamic Prediction of Mouse V1 Responses using V1T Core
                        Model<br /></a>
                        Z. Zhao and A. Onken<br />
                    <em>International Conference on Machine Learning</em> (<b>ICML</b>), 2021<br />
                    <p style="margin-top:3px">
                            [<a href="https://github.com/ermongroup/fast_feedforward_computation">Code</a>]
                    </p>
            </td>
    </tr>

    <!-- thesis -->
    <tr>
            <td valign="center">
                    <center>
                            <a href="https://tspace.library.utoronto.ca/handle/1807/106475"><img
                                            src="imgs/glass.png" alt="Link" width="200px" /></a>
                    </center>
            </td>

            <td valign="center">
                    <a href="https://tspace.library.utoronto.ca/handle/1807/106475">Deep Learning on Graphs:
                            Theory, Models, Algorithms and Applications<br /></a>
                    <b>Renjie Liao</b><br />
                    <em>PhD Thesis</em>, 2021<br />
            </td>
    </tr>

 

    <!-- paper -->


    <tr>
            <td valign="middle">
                    <center>
                            <a href="https://openreview.net/pdf?id=S1sqHMZCb"><img
                                            src="imgs/nerve_net_icon.png" alt="Link" width="200px" /></a>
                    </center>
            </td>

            <td valign="middle">
                    <a href="https://openreview.net/pdf?id=S1sqHMZCb">NerveNet: Learning Structured Policy
                            with Graph Neural Networks<br /></a> Tingwu Wang<b>*</b>, <b>Renjie Liao*</b>,
                    Jimmy Ba, Sanja Fidler<br />
                    <em>International Conference on Learning Representations</em> (<b>ICLR</b>), 2018<br />


                    <p style="margin-top:3px">[<a
                                    href="http://www.cs.toronto.edu/~tingwuwang/nervenet.html">Project</a>]
                            [<a href="https://github.com/WilsonWangTHU/NerveNet">Code</a>] [<a
                                    href="https://www.youtube.com/watch?v=ImSlirW1EI8&amp;feature=emb_logo">Video</a>]
                    </p>
            </td>
    </tr>
    <!-- paper -->


    <tr>
            <td valign="middle">
                    <center>
                            <a href="https://arxiv.org/abs/1803.02021"><img
                                            src="imgs/short_horizon_icon.png" alt="Link"
                                            width="150px" /></a>
                    </center>
            </td>

            <td valign="middle">
                    <a href="https://arxiv.org/abs/1803.02021">Understanding Short-Horizon Bias in
                            Stochastic Meta-Optimization<br /></a> Yuhuai Wu, Mengye Ren, <b>Renjie
                            Liao</b>, Roger Grosse<br />
                    <em>International Conference on Learning Representations</em> (<b>ICLR</b>), 2018<br />


                    <p style="margin-top:3px">[<a
                                    href="https://github.com/renmengye/meta-optim-public">Code</a>]</p>
            </td>
    </tr>
    <!-- paper -->


    <tr>
            <td valign="middle">
                    <center>
                            <a
                                    href="http://openaccess.thecvf.com/content_cvpr_2018/html/Qi_GeoNet_Geometric_Neural_CVPR_2018_paper.html"><img
                                            src="imgs/geo_net_icon.png" alt="Link" width="200px" /></a>
                    </center>
            </td>

            <td valign="middle">
                    <a href="papers/CVPR_2018_GeoNet.pdf">GeoNet: Geometric Neural Network for Joint Depth
                            and Surface Normal Estimation<br /></a> Xiaojuan Qi, <b>Renjie Liao</b>,
                    Zhengzhe Liu, Raquel Urtasun, Jiaya Jia<br />
                    <em>International Conference on Computer Vision and Pattern Recognition</em>
                    (<b>CVPR</b>), 2018<br />


                    <p style="margin-top:3px">[<a href="https://github.com/xjqi/GeoNet">Code</a>]</p>
            </td>
    </tr>
    <!-- paper -->


    <tr>
            <td valign="middle">
                    <center>
                            <a href="https://arxiv.org/abs/1803.06329"><img src="imgs/dsac_icon.png"
                                            alt="Link" width="200px" /></a>
                    </center>
            </td>

            <td valign="middle">
                    <a href="https://arxiv.org/abs/1803.06329">Learning Deep Structured Active Contours
                            End-to-End<br /></a> Diego Marcos, Devis Tuia, Benjamin Kellenberger, Lisa
                    Zhang, Min Bai, <b>Renjie Liao</b>, Raquel Urtasun<br />
                    <em>International Conference on Computer Vision and Pattern Recognition</em>
                    (<b>CVPR</b>), 2018<br />


                    <p style="margin-top:3px">[<a href="https://github.com/dmarcosg/DSAC">Code</a>] [<font
                                    color="red"><b>Spotlight Presentation, 224/3303 (6.8%)</b></font>]</p>
            </td>
    </tr>
    <!-- paper -->


    <tr>
            <td valign="middle">
                    <center>
                            <a
                                    href="http://openaccess.thecvf.com/content_iccv_2017/html/Qi_3D_Graph_Neural_ICCV_2017_paper.html"><img
                                            src="imgs/3D_gnn_icon.png" alt="Link" width="200px" /></a>
                    </center>
            </td>

            <td valign="middle">
                    <a
                            href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Qi_3D_Graph_Neural_ICCV_2017_paper.pdf">3D
                            Graph Neural Networks for RGBD Semantic Segmentation<br /></a> Xiaojuan Qi,
                    <b>Renjie Liao</b>, Jiaya Jia, Sanja Fidler, Raquel Urtasun<br />
                    <em>IEEE International Conference on Computer Vision</em> (<b>ICCV</b>), 2017<br />


                    <p style="margin-top:3px">[<a href="https://github.com/xjqicuhk/3DGNN">Code</a>] [ <a
                                    href="https://github.com/yanx27/3DGNN_pytorch">PyTorch
                                    Implementation</a> ] [<font color="red"><b>Oral Presentation, 45/2143
                                            (2.1%)</b></font>]</p>
            </td>
    </tr>
    <!-- paper -->


    <tr>
            <td valign="middle">
                    <center>
                            <a href="https://arxiv.org/abs/1708.04320"><img
                                            src="imgs/situation_gnn_icon.png" alt="Link"
                                            width="150px" /></a>
                    </center>
            </td>

            <td valign="middle">
                    <a href="https://arxiv.org/abs/1708.04320">Situation Recognition with Graph Neural
                            Networks<br /></a> Ruiyu Li, Makarand Tapaswi, <b>Renjie Liao</b>, Jiaya Jia,
                    Raquel Urtasun, Sanja Fidler<br />
                    <em>IEEE International Conference on Computer Vision</em> (<b>ICCV</b>), 2017<br />


                    <p style="margin-top:3px">[<a href="https://github.com/liruiyu/ggnn">Code</a>]</p>
            </td>
    </tr>
    <!-- paper -->


    <tr>
            <td valign="middle">
                    <center>
                            <a href="https://arxiv.org/abs/1704.02738"><img
                                            src="imgs/detail_video_sr_icon.png" alt="Link"
                                            width="200px" /></a>
                    </center>
            </td>

            <td valign="middle">
                    <a href="https://arxiv.org/abs/1704.02738">Detail-revealing Deep Video
                            Super-Resolution<br /></a> Xin Tao, Hongyun Gao, <b>Renjie Liao</b>, Jue Wang,
                    Jiaya Jia<br />
                    <em>IEEE International Conference on Computer Vision</em> (<b>ICCV</b>), 2017<br />


                    <p style="margin-top:3px">[<a href="https://github.com/jiangsutx/SPMC_VideoSR">Code</a>]
                            [<font color="red"><b>Oral Presentation, 45/2143 (2.1%)</b></font>]</p>
            </td>
    </tr>
    <!-- paper -->


    <tr>
            <td valign="middle">
                    <center>
                            <a href="https://arxiv.org/abs/1611.04520"><img src="imgs/div_norm_icon.png"
                                            alt="Link" width="200px" /></a>
                    </center>
            </td>

            <td valign="middle">
                    <a href="https://arxiv.org/abs/1611.04520">Normalizing the Normalizers: Comparing and
                            Extending Network Normalization Schemes<br /></a> Mengye Ren<b>*</b>, <b>Renjie
                            Liao*</b>, Raquel Urtasun, Fabian H. Sinz, Richard S. Zemel<br />
                    <em>International Conference on Learning Representations</em> (<b>ICLR</b>), 2017<br />


                    <p style="margin-top:3px">[<a href="https://github.com/renmengye/div-norm">Code</a>]</p>
            </td>
    </tr>
    <!-- paper -->


    <tr>
            <td valign="middle">
                    <center>
                            <a href="https://arxiv.org/abs/1511.06409"><img
                                            src="imgs/generation_perceptual_icon.png" alt="Link"
                                            width="200px" /></a>
                    </center>
            </td>

            <td valign="middle">
                    <a href="https://arxiv.org/abs/1511.06409">Learning to Generate Images with Perceptual
                            Similarity Metrics<br /></a> Jake Snell, Karl Ridgeway, <b>Renjie Liao</b>,
                    Brett D. Roads, Michael C. Mozer, Richard S. Zemel<br />
                    <em>International Conference on Image Processing</em> (<b>ICIP</b>), 2017<br />


                    <p style="margin-top:3px">
                    </p>
            </td>
    </tr>
    <!-- paper -->


    <tr>
            <td valign="middle">
                    <center>
                            <a
                                    href="https://papers.nips.cc/paper/6263-learning-deep-parsimonious-representations"><img
                                            src="imgs/parsimonious_icon.png" alt="Link" width="200px" /></a>
                    </center>
            </td>

            <td valign="middle">
                    <a
                            href="https://papers.nips.cc/paper/6263-learning-deep-parsimonious-representations.pdf">Learning
                            Deep Parsimonious Representation<br /></a> <b>Renjie Liao</b>, Alexander
                    Schwing, Richard S. Zemel, Raquel Urtasun<br />
                    <em>Neural Information Processing Systems</em> (<b>NIPS</b>), 2016<br />


                    <p style="margin-top:3px">[<a
                                    href="https://github.com/lrjconan/deep_parsimonious">Code</a>]</p>
            </td>
    </tr>
    <!-- paper -->


    <tr>
            <td valign="middle">
                    <center>
                            <a
                                    href="https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Liao_Video_Super-Resolution_via_ICCV_2015_paper.html"><img
                                            src="imgs/deep_draft_video_sr_icon.png" alt="Link"
                                            width="200px" /></a>
                    </center>
            </td>

            <td valign="middle">
                    <a
                            href="https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Liao_Video_Super-Resolution_via_ICCV_2015_paper.pdf">Video
                            Super-Resolution via Deep Draft-Ensemble Learning<br /></a> <b>Renjie Liao</b>,
                    Xin Tao, Ruiyu Li, Ziyang Ma, Jiaya Jia<br />
                    <em>IEEE International Conference on Computer Vision</em> (<b>ICCV</b>), 2015<br />


                    <p style="margin-top:3px">[<a
                                    href="http://www.cse.cuhk.edu.hk/leojia/projects/DeepSR/">Project &amp;
                                    Code</a>]</p>
            </td>
    </tr>
    <!-- paper -->


    <tr>
            <td valign="middle">
                    <center>
                            <a
                                    href="https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Qi_Semantic_Segmentation_With_ICCV_2015_paper.html"><img
                                            src="imgs/semantic_seg_clique_icon.png" alt="Link"
                                            width="200px" /></a>
                    </center>
            </td>

            <td valign="middle">
                    <a
                            href="https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Qi_Semantic_Segmentation_With_ICCV_2015_paper.pdf">Semantic
                            Segmentation With Object Clique Potential<br /></a> Xiaojuan Qi, Jianping Shi,
                    Shu Liu, <b>Renjie Liao</b>, Jiaya Jia<br />
                    <em>IEEE International Conference on Computer Vision</em> (<b>ICCV</b>), 2015<br />


                    <p style="margin-top:3px">
                    </p>
            </td>
    </tr>
    <!-- paper -->


    <tr>
            <td valign="middle">
                    <center>
                            <a
                                    href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Ma_Handling_Motion_Blur_2015_CVPR_paper.html"><img
                                            src="imgs/video_sr_blur_icon.png" alt="Link"
                                            width="200px" /></a>
                    </center>
            </td>

            <td valign="middle">
                    <a
                            href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Ma_Handling_Motion_Blur_2015_CVPR_paper.pdf">Handling
                            Motion Blur in Multi-Frame Super-Resolution<br /></a> Ziyang Ma, <b>Renjie
                            Liao</b>, Xin Tao, Li Xu, Jiaya Jia, Enhua Wu<br />
                    <em>International Conference on Computer Vision and Pattern Recognition</em>
                    (<b>CVPR</b>), 2015<br />


                    <p style="margin-top:3px">[<a
                                    href="http://www.cse.cuhk.edu.hk/~leojia/projects/mfsr/index.html">Project
                                    &amp; Code</a>]</p>
            </td>
    </tr>
    <!-- paper -->


    <tr>
            <td valign="middle">
                    <center>
                            <a href="http://proceedings.mlr.press/v37/xub15.html"><img
                                            src="imgs/deep_edge_filter_icon.png" alt="Link"
                                            width="200px" /></a>
                    </center>
            </td>

            <td valign="middle">
                    <a href="http://proceedings.mlr.press/v37/xub15.pdf">Deep Edge-Aware Filters<br /></a>
                    Li Xu, Jimmy Ren, Qiong Yan, <b>Renjie Liao</b>, Jiaya Jia<br />
                    <em>International Conference on Machine Learning</em> (<b>ICML</b>), 2015<br />


                    <p style="margin-top:3px">[<a
                                    href="https://github.com/jimmy-ren/vcnn_double-bladed/tree/master/applications/deep_edge_aware_filters">Code</a>]
                    </p>
            </td>
    </tr>
    <!-- paper -->


    <tr>
            <td valign="middle">
                    <center>
                            <a href="https://dl.acm.org/citation.cfm?id=2556238"><img
                                            src="imgs/npbus_icon.png" alt="Link" width="200px" /></a>
                    </center>
            </td>

            <td valign="middle">
                    <a href="./papers/WSDM_2014_NPBUS.pdf">Nonparametric Bayesian Upstream Supervised
                            Multi-Modal Topic Models<br /></a> <b>Renjie Liao</b>, Jun Zhu, Zengchang
                    Qin<br />
                    <em>ACM International Conference on Web Search and Data Mining</em> (<b>WSDM</b>),
                    2014<br />


                    <p style="margin-top:3px">
                    </p>
            </td>
    </tr>
    <!-- paper -->


    <tr>
            <td valign="middle">
                    <center>
                            <a
                                    href="https://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Lin_Learning_Important_Spatial_2014_CVPR_paper.html"><img
                                            src="imgs/important_spatial_pooling_icon.png" alt="Link"
                                            width="200px" /></a>
                    </center>
            </td>

            <td valign="middle">
                    <a
                            href="https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Lin_Learning_Important_Spatial_2014_CVPR_paper.pdf">Learning
                            Important Spatial Pooling Regions for Scene Classification<br /></a> Di Lin,
                    Cewu Lu, <b>Renjie Liao</b>, Jiaya Jia<br />
                    <em>International Conference on Computer Vision and Pattern Recognition</em>
                    (<b>CVPR</b>), 2014<br />


                    <p style="margin-top:3px">
                    </p>
            </td>
    </tr>
    <!-- paper -->


    <tr>
            <td valign="middle">
                    <center>
                            <a
                                    href="https://www.cv-foundation.org/openaccess/content_iccv_2013/html/Shi_CoDeL_A_Human_2013_ICCV_paper.html"><img
                                            src="imgs/codel_icon.png" alt="Link" width="200px" /></a>
                    </center>
            </td>

            <td valign="middle">
                    <a
                            href="https://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Shi_CoDeL_A_Human_2013_ICCV_paper.pdf">CoDeL:
                            An Efficient Human Co-detection and Labeling Framework<br /></a> Jianping
                    Shi<b>*</b>, <b>Renjie Liao*</b>, Jiaya Jia<br />
                    <em>IEEE International Conference on Computer Vision</em> (<b>ICCV</b>), 2013<br />


                    <p style="margin-top:3px">[<a href="http://shijianping.me/codel/index.html">Project</a>]
                    </p>
            </td>
    </tr>
    <!-- paper -->


    <tr>
            <td valign="middle">
                    <center>
                            <a href="https://link.springer.com/chapter/10.1007/978-3-642-37431-9_27"><img
                                            src="imgs/kernel_regression_sr_icon.png" alt="Link"
                                            width="200px" /></a>
                    </center>
            </td>

            <td valign="middle">
                    <a href="./papers/ACCV_2012_SR.pdf">Image Super-Resolution Using Local Learnable Kernel
                            Regression<br /></a> <b>Renjie Liao</b>, Zengchang Qin<br />
                    <em>Asian Conference on Computer Vision</em> (<b>ACCV</b>), 2012<br />


                    <p style="margin-top:3px">[<a href="./code/SR_LLKR.zip">Code</a>]</p>
            </td>
    </tr>
</table>


<h1 id="preprints">Preprints</h1>

<table border="0" cellspacing="10" cellpadding="2">
    <!-- paper -->
    <tr>
            <td valign="center">
                    <center>
                            <a href="https://arxiv.org/abs/1907.13079"><img
                                            src="imgs/deformable_conv_icon.png" alt="Link"
                                            width="200px" /></a>
                    </center>
            </td>

            <td valign="center">
                    <a href="https://arxiv.org/abs/1907.13079">Deformable Filter Convolution for Point Cloud
                            Reasoning<br /></a> Yuwen Xiong, Mengye Ren, <b>Renjie Liao</b>, Kelvin Wong,
                    Raquel Urtasun<br />
                    arXiv preprint arXiv:1907.13079 (2019)<br />

                    <p style="margin-top:3px">
                    </p>
            </td>
    </tr>
</table>
